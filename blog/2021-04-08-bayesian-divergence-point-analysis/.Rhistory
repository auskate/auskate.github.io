library(tidyverse)
install.packages("RMarkdown")
install.packages("Rtools")
install.packages("RMarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("papaja")
install.packages("devtools")
devtools::install_github("crsh/papaja")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
devtools::install_github("crsh/papaja")
install.packages("tidytex")
install.packages("tinytex")
install.packages("citr")
tinytex::install_tinytex()
remove.packages("tinytex")
R.Version()
setwd("E:/Academic/AGREE/papers/L1/OSF")
library(tidyverse)
# load
dat_raw <- read.table("./../data/data_experiment2.txt", header = TRUE)
# clean
dat_exp2 <- dat_raw %>%
filter(Blink == 0 & Saccade == 0 &
Accuracy_Possessee == 1 &
Interest_Area == 1,
!(Naming %in% c("incorrect", "gender_error"))) %>%
select(-Blink, -Saccade, -Accuracy_Possessee, -Interest_Area)
# prepare data
head(boot_data_exp2 <- dat_exp2 %>%
# adjective onset to noun onset + 300 ms buffer
filter(between(Time, 0, 1800) &
Condition %in% c("match","mismatch")) %>%
mutate(StrataVars = paste(Participant, Condition, Region, Time, sep = "")) %>%
droplevels())
boot_data_exp2$StrataVars <- as.factor(boot_data_exp2$StrataVars)
boot_data_exp2$Participant <- as.factor(boot_data_exp2$Participant)
# bootstrap function
boot_exp2 <- function(original_data, resample_indices, criterion){
# resample the data
dat_resample <- original_data[resample_indices, ]
# update progress bar
progress$tick()
# sum and average fixations over items at each timebin
dat <- dat_resample %>%
filter(Value == 1) %>%
mutate(pTarget = ifelse(Region=="target_ia", 1, 0)) %>%
group_by(Participant, Condition, Time) %>%
summarise(SumFixation  = sum(pTarget),
NFixation    = length(pTarget),
MeanFixation = mean(pTarget), .groups = "keep")
# sanity check plot: this will now give chance fixation of 50%
# dat %>%
#   ggplot(aes(Time, MeanFixation)) +
#   geom_smooth() +
#   geom_hline(yintercept = .5) +
#   geom_vline(xintercept = 900, linetype = "dashed") +
#   facet_grid(.~Condition)
# find t-value for each timebin in each condition
test_match <- dat %>%
filter(Condition == "match") %>%
# create the empirical logits by region
mutate(elog = log((SumFixation +.5)/(NFixation-SumFixation + .5)),
# variances
vs = 1/(SumFixation +.5) + 1/(NFixation-SumFixation + .5),
# weights
wts = 1/vs) %>%
ungroup() %>%
group_by(Time) %>%
# apply the linear model
summarise(t = summary(lm(elog ~ 1, weights = wts))$coefficients[1,3]) %>%
# mark TRUE/FALSE which are part of <criterion> significant t-values in a row
mutate(significant = zoo::rollsum(t > 1.96, criterion, na.pad = TRUE, align = "left") >= criterion)
test_mismatch <- dat %>%
filter(Condition == "mismatch") %>%
# create the empirical logits by region
mutate(elog = log((SumFixation +.5)/(NFixation-SumFixation + .5)),
# variances
vs = 1/(SumFixation +.5) + 1/(NFixation-SumFixation + .5),
# weights
wts = 1/vs) %>%
ungroup() %>%
group_by(Time) %>%
# apply the linear model
summarise(t = summary(lm(elog ~ 1, weights = wts))$coefficients[1,3]) %>%
# mark TRUE/FALSE which are part of <criterion> significant t-values in a row
mutate(significant = zoo::rollsum(t > 1.96, criterion, na.pad = TRUE, align = "left") >= criterion)
# extract the earliest time with a run of <criterion> significant t-values
onset_match    <- subset(test_match, significant == TRUE)[1, "Time"]
onset_mismatch <- subset(test_mismatch, significant == TRUE)[1, "Time"]
# print the result
unlist(c(
as.numeric(onset_match),    # position in resulting "bootresult": t[,1]
as.numeric(onset_mismatch)  # position in resulting "bootresult": t[,2]
))
}
# set number of iterations; 1000-2000 is sufficient
Niter <- 2000
# initialise progress bar
progress <- progress::progress_bar$new(total = Niter + 1, clear = FALSE, format = "[:bar] :percent :eta")
# run the bootstrap
bootresult_exp2 <- boot::boot(data = boot_data_exp2,            # which data to use
statistic = boot_exp2,               # which function to use
criterion = 5,                       # how many significant t-values in a row equals an "onset"
strata = boot_data_exp2$StrataVars,  # which variable to stratify by
R = Niter)                           # how many times to resample
# bootstrap function
boot_exp2 <- function(original_data, resample_indices, criterion){
# resample the data
dat_resample <- original_data[resample_indices, ]
# update progress bar
progress$tick()
# sum and average fixations over items at each timebin
dat <- dat_resample %>%
filter(Value == 1) %>%
mutate(pTarget = ifelse(Region=="target_ia", 1, 0)) %>%
group_by(Participant, Condition, Time) %>%
summarise(SumFixation  = sum(pTarget),
NFixation    = length(pTarget),
MeanFixation = mean(pTarget))
# sanity check plot: this will now give chance fixation of 50%
# dat %>%
#   ggplot(aes(Time, MeanFixation)) +
#   geom_smooth() +
#   geom_hline(yintercept = .5) +
#   geom_vline(xintercept = 900, linetype = "dashed") +
#   facet_grid(.~Condition)
# find t-value for each timebin in each condition
test_match <- dat %>%
filter(Condition == "match") %>%
# create the empirical logits by region
mutate(elog = log((SumFixation +.5)/(NFixation-SumFixation + .5)),
# variances
vs = 1/(SumFixation +.5) + 1/(NFixation-SumFixation + .5),
# weights
wts = 1/vs) %>%
ungroup() %>%
group_by(Time) %>%
# apply the linear model
summarise(t = summary(lm(elog ~ 1, weights = wts))$coefficients[1,3]) %>%
# mark TRUE/FALSE which are part of <criterion> significant t-values in a row
mutate(significant = zoo::rollsum(t > 1.96, criterion, na.pad = TRUE, align = "left") >= criterion)
test_mismatch <- dat %>%
filter(Condition == "mismatch") %>%
# create the empirical logits by region
mutate(elog = log((SumFixation +.5)/(NFixation-SumFixation + .5)),
# variances
vs = 1/(SumFixation +.5) + 1/(NFixation-SumFixation + .5),
# weights
wts = 1/vs) %>%
ungroup() %>%
group_by(Time) %>%
# apply the linear model
summarise(t = summary(lm(elog ~ 1, weights = wts))$coefficients[1,3]) %>%
# mark TRUE/FALSE which are part of <criterion> significant t-values in a row
mutate(significant = zoo::rollsum(t > 1.96, criterion, na.pad = TRUE, align = "left") >= criterion)
# extract the earliest time with a run of <criterion> significant t-values
onset_match    <- subset(test_match, significant == TRUE)[1, "Time"]
onset_mismatch <- subset(test_mismatch, significant == TRUE)[1, "Time"]
# print the result
unlist(c(
as.numeric(onset_match),    # position in resulting "bootresult": t[,1]
as.numeric(onset_mismatch)  # position in resulting "bootresult": t[,2]
))
}
# initialise progress bar
progress <- progress::progress_bar$new(total = Niter + 1, clear = FALSE, format = "[:bar] :percent :eta")
# run the bootstrap
bootresult_exp2 <- boot::boot(data = boot_data_exp2,            # which data to use
statistic = boot_exp2,               # which function to use
criterion = 5,                       # how many significant t-values in a row equals an "onset"
strata = boot_data_exp2$StrataVars,  # which variable to stratify by
R = Niter)                           # how many times to resample
rm(dat_raw)
gc()
# bootstrap function
boot_exp2 <- function(original_data, resample_indices, criterion){
# resample the data
dat_resample <- original_data[resample_indices, ]
# update progress bar
progress$tick()
# sum and average fixations over items at each timebin
dat <- dat_resample %>%
filter(Value == 1) %>%
mutate(pTarget = ifelse(Region=="target_ia", 1, 0)) %>%
group_by(Participant, Condition, Time) %>%
summarise(SumFixation  = sum(pTarget),
NFixation    = length(pTarget),
MeanFixation = mean(pTarget), .groups = "keep")
# sanity check plot: this will now give chance fixation of 50%
# dat %>%
#   ggplot(aes(Time, MeanFixation)) +
#   geom_smooth() +
#   geom_hline(yintercept = .5) +
#   geom_vline(xintercept = 900, linetype = "dashed") +
#   facet_grid(.~Condition)
# find t-value for each timebin in each condition
test_match <- dat %>%
filter(Condition == "match") %>%
# create the empirical logits by region
mutate(elog = log((SumFixation +.5)/(NFixation-SumFixation + .5)),
# variances
vs = 1/(SumFixation +.5) + 1/(NFixation-SumFixation + .5),
# weights
wts = 1/vs) %>%
ungroup() %>%
group_by(Time) %>%
# apply the linear model
summarise(t = summary(lm(elog ~ 1, weights = wts))$coefficients[1,3]) %>%
# mark TRUE/FALSE which are part of <criterion> significant t-values in a row
mutate(significant = zoo::rollsum(t > 1.96, criterion, na.pad = TRUE, align = "left") >= criterion)
test_mismatch <- dat %>%
filter(Condition == "mismatch") %>%
# create the empirical logits by region
mutate(elog = log((SumFixation +.5)/(NFixation-SumFixation + .5)),
# variances
vs = 1/(SumFixation +.5) + 1/(NFixation-SumFixation + .5),
# weights
wts = 1/vs) %>%
ungroup() %>%
group_by(Time) %>%
# apply the linear model
summarise(t = summary(lm(elog ~ 1, weights = wts))$coefficients[1,3]) %>%
# mark TRUE/FALSE which are part of <criterion> significant t-values in a row
mutate(significant = zoo::rollsum(t > 1.96, criterion, na.pad = TRUE, align = "left") >= criterion)
# extract the earliest time with a run of <criterion> significant t-values
onset_match    <- subset(test_match, significant == TRUE)[1, "Time"]
onset_mismatch <- subset(test_mismatch, significant == TRUE)[1, "Time"]
# print the result
unlist(c(
as.numeric(onset_match),    # position in resulting "bootresult": t[,1]
as.numeric(onset_mismatch)  # position in resulting "bootresult": t[,2]
))
}
# set number of iterations; 1000-2000 is sufficient
Niter <- 2000
# initialise progress bar
progress <- progress::progress_bar$new(total = Niter + 1, clear = FALSE, format = "[:bar] :percent :eta")
# run the bootstrap
bootresult_exp2 <- boot::boot(data = boot_data_exp2,            # which data to use
statistic = boot_exp2,               # which function to use
criterion = 5,                       # how many significant t-values in a row equals an "onset"
strata = boot_data_exp2$StrataVars,  # which variable to stratify by
R = Niter)                           # how many times to resample
blogdown:::preview_site()
blogdown:::preview_site()
blogdown:::preview_site()
blogdown:::preview_site()
blogdown:::preview_site()
values
blogdown:::preview_site()
# load
dat_raw <- read.table("./../data/data_experiment2.txt", header = TRUE)
# clean
dat_exp2 <- dat_raw %>%
filter(Blink == 0 & Saccade == 0 &
Accuracy_Possessee == 1 &
Interest_Area == 1,
!(Naming %in% c("incorrect", "gender_error"))) %>%
select(-Blink, -Saccade, -Accuracy_Possessee, -Interest_Area)
# create plotting data
plot_exp2 <- dat_exp2 %>%
filter(between(Time, 0, 1900) & Condition %in% c("match","mismatch")) %>%
# downsample to every 100ms
filter(Time %% 50 == 0) %>%
# rename and reorder factor levels
mutate(Region = fct_relevel(fct_recode(Region, target = "target_ia",
competitor = "ccolor_ia"), "target")) %>%
# create mean fixation proportions by participant
group_by(Participant, Condition, Region, Time) %>%
summarise(MeanFixation = mean(Value))
head(plot_exp2)
ggplot(plot_exp2, aes(Time, MeanFixation)) +
stat_summary(fun.data = mean_cl_boot,
aes(fill = Region), geom = "ribbon", alpha = .25, show.legend = FALSE) +
stat_summary(fun = mean, geom = "path",
aes(group = Region, colour = Region, linetype = Region), size = 1) +
facet_grid(.~ Condition, labeller = as_labeller(facet_names)) +
# add vertical lines for time windows
geom_hline(yintercept = .5, linetype = "dotted") +
geom_vline(xintercept = onsets, linetype = "dashed", colour = "grey50")
# general plot settings
col         <- c("#08519C","#08519C")
facet_names <- c(match = "Match", mismatch = "Mismatch")
onsets      <- c(800, 1800)
lty         <- c("solid", "dotdash")
# data frame for adding words to the plot
words <- data.frame(plot_exp2) %>%
select(c("Condition")) %>%
distinct(.keep_all=TRUE)
setwd("C:/repos/website/content/drafts/2021-02-19-bayesian-divergence-point-analysis")
blogdown:::preview_site()
blogdown:::preview_site()
blogdown:::preview_site()
blogdown:::preview_site()
blogdown:::preview_site()
blogdown:::preview_site()
705-369
sqrt(9^2+22^2)
336-(2*24)
336+(2*24)
# bootstrap data
bootres_exp2 <- readRDS("E:/Academic/AGREE/papers/L1/data/bootres_spritzer_L1paper_250Hz.rds")
# tidy bootstrap dataframes
bootstrap_samples <- data.frame(dp = bootres_exp2$t[,1]*20,
match = (bootres_exp2$t[,2]-1)*20,
mismatch = (bootres_exp2$t[,3]-1)*20)
mean(bootres_exp2$t[,1], na.rm = TRUE)*20
boot::boot.ci(bootres_exp2, index = 1,
type = "perc")$percent[4]*20
boot::boot.ci(bootres_exp2, index = 1,
type = "perc")$percent[5]*20
